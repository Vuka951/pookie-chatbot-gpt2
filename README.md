# 🌟 Pookie Chatbot Project (GPT2) 🌟

## 💬 Project Overview

Welcome to the **Pookie Chatbot Project**, where magic happens! ✨ The goal? To fine-tune a GPT-2 model into a Pookie that understands you like a soulmate and responds with just the right touch of flair. 😘 Think of it as your AI Pookie 💕

---

## ❤️ Goals of the Project

- Create a chatbot that feels like it’s stealing your heart with every response. 💖
- Fine-tune GPT-2 to handle multi-turn conversations with finesse. 🧠
- Achieve a loss value of approximately **1.5** through dedication and a little bit of magic. ✨

---

## 📂 File Structure

Here’s the treasure map to our files, because organization is sexy:

### 1. **`setup_pookie_chatbot.py`**

- **Purpose**: Kicks things off by creating your custom tokenizer and a fresh GPT-2 model by doing a lobotomy on the standard GPT2 model. 🎉
- **Key Steps**:
  - Trains a Byte Pair Encoding (BPE) tokenizer with special tokens like `<user>`, `<system>`, and `<sep>`. 🧵
  - Configures and saves a fresh lobotomized GPT-2 model with a vocabulary size that matches the tokenizer. 🪄

### 2. **`train_pookie.py`**

- **Purpose**: Fine-tune the GPT-2 model to perfection. 💪
- **Key Steps**:
  - Loads the custom tokenizer and dataset. 📚
  - Sets up training configurations (think batch size, learning rate, and other spicy details), the configuration are setup for slight overfitting 🌶️
  - Trains the model for multiple epochs (10 or more for best results since we have a small dataset). 🔄
  - Saves the fine-tuned model and tokenizer in the `pookie-chatbot` directory. 🏦
  - Cleans up intermediate checkpoints because clutter isn’t cute and takes up too much space. 🧹

### 3. **`run_pookie_chatbot.py`**

- **Purpose**: The main attraction! Interact with your chatbot in a fun, flirty, and fabulous way. 🥳
- **Key Steps**:
  - Loads your fine-tuned GPT-2 model and tokenizer. 📤
  - Lets you chat endlessly while the chatbot keeps up with multi-turn conversations. 💬
  - Formats the conversation with special tokens to keep it spicy. 🔥

### 4. **`custom_tokenizer.json`**

- **Purpose**: Stores the trained custom tokenizer configuration and vocabulary. 🛠️
- **Generated By**: `setup_pookie_chatbot.py`.

### 5. **`datasets`**

- **Purpose**: Your treasure trove of `.txt` files for training. 🗂️
- **Notes**:
  - Fill this folder with juicy, meaningful conversations. 🥰
  - These files will be combined and tokenized during training. 🧩

### 6. **`pookie-chatbot`**

- **Purpose**: The vault for your fine-tuned model and tokenizer. 💎
- **Generated By**: `train_pookie.py`.

---

## 🚀 Project Workflow

Follow this smooth, seductive workflow to get your chatbot grooving:

1. **Setup**

   - Run `setup_pookie_chatbot.py` to create your custom tokenizer and initialize a fresh GPT-2 model. 🛠️
   - Only do this once unless you’re feeling adventurous and want to tweak the tokenizer or dataset. 😉

2. **Training**

   - Run `train_pookie.py` to fine-tune your model. 🏋️‍♂️
   - Repeat training **10 or more times** to achieve that sweet spot of a loss around **1.5**. The more you train, the better it gets (just like flirting). 😘

3. **Testing the Chatbot**
   - Once fine-tuned, run `run_pookie_chatbot.py` to test your chatbot in an interactive session. 🎭
   - Watch as it dazzles you with coherent (not really), context-aware(not really) responses. 🌟

---

## 🔮 Additional Notes

- If you have any suggestions for improvements or find any issue pleause open a pull request
- On the other hand if you had a fun time using this code please do star the repo and spread some love 🫶
