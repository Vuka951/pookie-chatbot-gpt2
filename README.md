# ğŸŒŸ Pookie Chatbot Project (GPT2) ğŸŒŸ

## ğŸ’¬ Project Overview

Welcome to the **Pookie Chatbot Project**, where magic happens! âœ¨ The goal? To fine-tune a GPT-2 model into a Pookie that understands you like a soulmate and responds with just the right touch of flair. ğŸ˜˜ Think of it as your AI Pookie ğŸ’•

---

## â¤ï¸ Goals of the Project

- Create a chatbot that feels like itâ€™s stealing your heart with every response. ğŸ’–
- Fine-tune GPT-2 to handle multi-turn conversations with finesse. ğŸ§ 
- Achieve a loss value of approximately **1.5** through dedication and a little bit of magic. âœ¨

---

## ğŸ“‚ File Structure

Hereâ€™s the treasure map to our files, because organization is sexy:

### 1. **`setup_pookie_chatbot.py`**

- **Purpose**: Kicks things off by creating your custom tokenizer and a fresh GPT-2 model by doing a lobotomy on the standard GPT2 model. ğŸ‰
- **Key Steps**:
  - Trains a Byte Pair Encoding (BPE) tokenizer with special tokens like `<user>`, `<system>`, and `<sep>`. ğŸ§µ
  - Configures and saves a fresh lobotomized GPT-2 model with a vocabulary size that matches the tokenizer. ğŸª„

### 2. **`train_pookie.py`**

- **Purpose**: Fine-tune the GPT-2 model to perfection. ğŸ’ª
- **Key Steps**:
  - Loads the custom tokenizer and dataset. ğŸ“š
  - Sets up training configurations (think batch size, learning rate, and other spicy details), the configuration are setup for slight overfitting ğŸŒ¶ï¸
  - Trains the model for multiple epochs (10 or more for best results since we have a small dataset). ğŸ”„
  - Saves the fine-tuned model and tokenizer in the `pookie-chatbot` directory. ğŸ¦
  - Cleans up intermediate checkpoints because clutter isnâ€™t cute and takes up too much space. ğŸ§¹

### 3. **`run_pookie_chatbot.py`**

- **Purpose**: The main attraction! Interact with your chatbot in a fun, flirty, and fabulous way. ğŸ¥³
- **Key Steps**:
  - Loads your fine-tuned GPT-2 model and tokenizer. ğŸ“¤
  - Lets you chat endlessly while the chatbot keeps up with multi-turn conversations. ğŸ’¬
  - Formats the conversation with special tokens to keep it spicy. ğŸ”¥

### 4. **`custom_tokenizer.json`**

- **Purpose**: Stores the trained custom tokenizer configuration and vocabulary. ğŸ› ï¸
- **Generated By**: `setup_pookie_chatbot.py`.

### 5. **`datasets`**

- **Purpose**: Your treasure trove of `.txt` files for training. ğŸ—‚ï¸
- **Notes**:
  - Fill this folder with juicy, meaningful conversations. ğŸ¥°
  - These files will be combined and tokenized during training. ğŸ§©

### 6. **`pookie-chatbot`**

- **Purpose**: The vault for your fine-tuned model and tokenizer. ğŸ’
- **Generated By**: `train_pookie.py`.

---

## ğŸš€ Project Workflow

Follow this smooth, seductive workflow to get your chatbot grooving:

1. **Setup**

   - Run `setup_pookie_chatbot.py` to create your custom tokenizer and initialize a fresh GPT-2 model. ğŸ› ï¸
   - Only do this once unless youâ€™re feeling adventurous and want to tweak the tokenizer or dataset. ğŸ˜‰

2. **Training**

   - Run `train_pookie.py` to fine-tune your model. ğŸ‹ï¸â€â™‚ï¸
   - Repeat training **10 or more times** to achieve that sweet spot of a loss around **1.5**. The more you train, the better it gets (just like flirting). ğŸ˜˜

3. **Testing the Chatbot**
   - Once fine-tuned, run `run_pookie_chatbot.py` to test your chatbot in an interactive session. ğŸ­
   - Watch as it dazzles you with coherent (not really), context-aware(not really) responses. ğŸŒŸ

---

## ğŸ”® Additional Notes

- If you have any suggestions for improvements or find any issue pleause open a pull request
- On the other hand if you had a fun time using this code please do star the repo and spread some love ğŸ«¶
